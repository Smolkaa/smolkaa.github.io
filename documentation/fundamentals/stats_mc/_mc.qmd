The Monte Carlo method, a pivotal computational technique in various fields, traces its origins to the mid-20th century. It was developed by scientists, notably Stanislaw Ulam and John von Neumann, at the Los Alamos National Laboratory during the Manhattan Project in the 1940s. The name "Monte Carlo" was inspired by the Monte Carlo Casino in Monaco, known for its games of chance and randomness, reflecting the method's reliance on random sampling and probabilistic principles. Initially applied to solve complex mathematical and physical problems related to nuclear physics and neutron diffusion, the Monte Carlo method rapidly expanded its utility to diverse scientific and engineering domains. Its historical significance lies not only in its role during the development of the atomic bomb but also in its enduring impact on modern computational science, enabling the simulation and analysis of intricate systems and processes. [@Barbu2020; @Lemieux2009]

The Monte Carlo method's applicability has transcended its origins and found widespread use across numerous disciplines, including physics, chemistry, engineering, finance, biology, computer graphics, and operations research. In these fields, realistic models often incorporate the assumption that specific components within systems show random behavior. The Monte Carlo simulation method addresses this by leveraging random sampling techniques to study the properties of systems characterized by stochastic components. Specifically, it involves the computer-based simulation of such systems by generating random variables that describe the behavior of their components. Subsequently, samples of the quantities of interest are obtained through this simulated randomness, facilitating statistical inference and analysis. This versatile and probabilistic approach has made the Monte Carlo method an indispensable tool for addressing complex and stochastic problems in various scientific and practical domains. [@Lemieux2009]


## Basics Simulation Setup

Generally speaking, a Monte Carlo simulation is not restricted to any fixed physical system or model but rather describes the method used to simulate the individual problem. Its general structure is presented in @fig-mc_basic, showing that a Monte Carlo simulation only consists of an initialization and a loop. The initialization step involves setting up the system and its components, including the specification of the system's state, the random number generator seed, and setting global parameters, most importantly the number of Monte Carlo steps $N$. The loop then iterates over the $N$ Monte Carlo steps.

{{< include stats_mc/imgs/mc_basic/_mc_basic.qmd >}}

In the context of Monte Carlo simulations, the system under examination is exclusively represented within the iterative process, specifically encapsulated within the Monte Carlo step. This step encompasses various deterministic and probabilistic subsystems, emphasizing the probabilistic aspect inherent to Monte Carlo simulations. While it is unquestionably preferable to solve both the deterministic and probabilistic components of the system analytically, their combination becomes exceedingly complex quite rapidly, necessitating numerical methods. Each Monte Carlo step effectively addresses the system employing probabilistic sampling, engendering not a definitive solution but rather a singular realization of the probabilistic system. As the number of Monte Carlo steps increases, a correspondingly growing quantity of samples is generated. Therefore, collecting these samples enables a comprehensive analysis of the system's statistical properties.

In the context of this work, examples of probabilistic subsystems can be found in many of the underlying physical processes like the energy, velocity, and angle distributions of the various mechanisms in the exosphere and during surface interactions, for example, the section about [Thermal Sorption](/documentation/drivers/thermal_sorption.qmd), as well as the handling of probabilistic events like [photoionization and -dissociation](/documentation/drivers/photoreactions.qmd), [sputtering](), and [Photon and Electron Stimulated Desorption](/documentation/drivers/), to just name a few. Additionally, some parameters of the system are either inherently stochastic (like binding energies) or are implemented as such to either account for their uncertainty or to allow for a more realistic simulation. Examples of the latter are the [surface geometry]() and the [surface temperatures](/documentation/fundamentals/moon.qmd), which are both modeled as random variables. Examples of deterministic systems are all those calculations that can be performed analytically, like the [landing position calculations](/documentation/trajectories/ballistic_trajectories.qmd) of purely ballistic trajectories.


## Sampling from Probability Distributions

One of the most important tasks of any Monte Carlo method is to sample from known probability distributions. This important step can be either done by using a predefined method, like `rand` (a uniform distribution with the domain $\left[0, 1\right]$) and `randn` (a normal distribution with the domain $\left(-\infty, \infty \right)$) for the Julia Programming language, or by using more complex methods like inversion [@Lemieux2009]. The latter is especially useful when any kind of known, but more complex distribution than a uniform or normal distribution shall be sampled. The main process involves mapping the random number sampled from a uniform distribution between $\num{0}$ and $\num{1}$ to the CDF of the desired distribution. 

Let $\randomVariableUniform\in\left[0,1\right]$ be the random variable of a uniform distribution with realization $\randomValueUniform$ of $\randomVariableUniform \sim f(\randomValueUniform) = 1$, and let $\randomVariable$ be the random variable of the desired distribution with realization $\randomValue$ of $\randomVariable \sim f(\randomValue)$. The CDF of $\randomVariable$, defined as $F(\randomVariable)$, already matches the domain of $\randomVariableUniform$ and can directly be mapped to it by $\randomVariableUniform = F(\randomVariable)$. Inversion now inverts the statement to $\randomVariable = F^{-1}(\randomVariableUniform)$ to obtain the realization $\randomValue$ of $\randomVariable$ from the realization $\randomValueUniform$ of $\randomVariableUniform$. 

::: {.callout-note collapse="true"}

# Inversion example: $f(x) = \frac{1}{2}\cos x$

While this approach appears to be quite simple, it greatly depends on the difficulty to derive the CDF's inverse $F^{-1}$. For example, let the PDF of the random variable $\randomVariable\in\left[-\pi / 2, \pi / 2 \right]$ be given by 
\begin{equation}
    \randomValue \sim f(\randomValue) = \frac{1}{2}\cos \randomValue
\end{equation}
(which is the elevation angle distribution of the [Maxwell-Boltzmann velocity distribution](/documentation/drivers/thermal_sorption.qmd)). The CDF can easily be derived as 
\begin{equation}
    F(\randomValue) = \frac{1}{2} \left( \sin \randomValue + 1 \right).
\end{equation}
We can now draw a random uniform number $\randomValueUniform$ of $\randomVariableUniform\in\left[0, 1\right]$, set this equal to $F(\randomValue)$, and solve for $\randomValue$ to obtain the inverse CDF $F^{-1}(\randomValueUniform)$:
\begin{align}
    \randomValueUniform &= \frac{1}{2} \left( \sin \randomValue + 1 \right) \\
    \sin \randomValue &= 2 \randomValueUniform - 1 \\
    \randomValue &= \sin^{-1} \left( 2 \randomValueUniform - 1 \right).
\end{align}


TEST THIS HERE!!!

:::